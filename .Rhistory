axis.title = element_text(size = 12),
axis.text = element_text(size = 10)
)
# Generate sample data from two normal distributions
set.seed(1823)
data1 <- rnorm(1000, mean = 0, sd = 1)
data2 <- rnorm(1000, mean = 3, sd = 1)
data <- c(data1, data2)
# Kernel density estimation for mixed distribution
density_mix <- density(data)
# Plot the kernel density
plot(density_mix, main = "Kernel Density Plot for Mixed Distribution",
xlab = "X", ylab = "Density")
# Load necessary libraries
library(ggplot2)
library(dbscan)
# Generate synthetic data
set.seed(42)
n <- 100
data <- data.frame(
x = c(rnorm(n, mean = 0, sd = 0.3), rnorm(n, mean = 1, sd = 0.3)),
y = c(rnorm(n, mean = 0, sd = 0.3), rnorm(n, mean = 1, sd = 0.3))
)
# Plot the initial data
ggplot(data, aes(x, y)) +
geom_point() +
ggtitle("Step 1: Initial Data") +
theme_minimal()
# DBSCAN parameters
eps <- 0.2
minPts <- 5
# Identify core points
db <- dbscan(data, eps = eps, minPts = minPts)
data$core <- ifelse(db$cluster > 0, "Core", "Noise")
ggplot(data, aes(x, y, color = core)) +
geom_point() +
scale_color_manual(values = c("Core" = "blue", "Noise" = "red")) +
ggtitle("Step 2: Core Points and Noise") +
theme_minimal()
# Cluster formation
data$cluster <- as.factor(db$cluster)
ggplot(data, aes(x, y, color = cluster)) +
geom_point() +
scale_color_manual(values = c("0" = "red", "1" = "blue", "2" = "green")) +
ggtitle("Step 3: Cluster Formation") +
theme_minimal()
# Step-by-step process
plot_dbscan_steps <- function(data, eps, minPts) {
db <- dbscan(data[, 1:2], eps = eps, minPts = minPts)
data$cluster <- as.factor(db$cluster)
data$core <- ifelse(db$cluster > 0, "Core", "Noise")
ggplot(data, aes(x, y, color = cluster, shape = core)) +
geom_point(size = 3) +
scale_color_manual(values = c("0" = "red", "1" = "blue", "2" = "green")) +
scale_shape_manual(values = c("Core" = 16, "Noise" = 1)) +
ggtitle("DBSCAN Clustering Step by Step") +
theme_minimal()
}
# Plot the final result
plot_dbscan_steps(data, eps, minPts)
library(ggplot2)
library(animation)
library(dbscan)
# Generate sample data for 3 clusters
set.seed(123)
x <- c(rnorm(50, 0, 2), rnorm(50, 8, 2), rnorm(50, -8, 2))
y <- c(rnorm(50, 0, 2), rnorm(50, 8, 2), rnorm(50, -8, 2))
data <- data.frame(x, y)
# Perform DBSCAN clustering
db <- dbscan(data, eps = 2, minPts = 5)
# Extract core points and their cluster labels
core_points <- data[db$cluster != 0, ]
core_labels <- db$cluster[db$cluster != 0]
# Function to create animation frames
animate_dbscan <- function(data, db, core_points, core_labels) {
frames <- list()
# Initial frame with all core points in blue and noise in gray
initial_plot <- ggplot() +
geom_point(data = data, aes(x, y), color = ifelse(db$cluster == 0, "black", "blue"), size = 3) +
labs(title = "DBSCAN Clustering (Initial)") +
theme_minimal()
frames[[1]] <- initial_plot
# Clusters
cluster_colors <- c("#FF0000", "#0000FF", "#00FF00")  # Red, Blue, Green
unique_labels <- unique(core_labels)
frame_counter <- 2
for (cluster_index in seq_along(unique_labels)) {
cluster_label <- unique_labels[cluster_index]
cluster_points <- data[db$cluster == cluster_label, ]
for (point_index in 1:nrow(cluster_points)) {
current_core <- core_points[core_labels == cluster_label, ][1:point_index, ]
p <- ggplot() +
geom_point(data = data, aes(x, y), color = ifelse(db$cluster == 0, "black", "gray80"), size = 3) +
geom_point(data = cluster_points[1:point_index, ], aes(x, y), color = cluster_colors[cluster_index], size = 5) +
labs(title = paste("DBSCAN Clustering (Frame", frame_counter, ")")) +
theme_minimal()
frames[[frame_counter]] <- p
frame_counter <- frame_counter + 1
}
}
# Final frame showing all clusters in their respective colors
final_plot <- ggplot() +
geom_point(data = data, aes(x, y), color = ifelse(db$cluster == 0, "black", "gray80"), size = 3) +
geom_point(data = core_points, aes(x, y, color = factor(core_labels)), size = 5) +
scale_color_manual(values = cluster_colors) +
labs(title = "DBSCAN Clustering (Final)", color = "Cluster") +
theme_minimal()
frames[[frame_counter]] <- final_plot
return(frames)
}
# Create animation frames
frames <- animate_dbscan(data, db, core_points, core_labels)
# Create animation
ani.options(interval = 0.5)
saveGIF({
for (i in seq_along(frames)) {
print(frames[[i]])
}
}, movie.name = "dbscan_animation.gif", ani.width = 600, ani.height = 600)
library(pan)
?pan
# Set Directory
setwd("/Users/tipusultan/Documents/GitHub/Imputation-of-Panel-Data")
library(dplyr)
library(readxl)
# Load and clean the data
RawData <- readRDS("population.RDS")
RawData = data.frame(RawData)
data = RawData[c("id", "year","EF310", "ind.median", "inc.ind")]
colnames(data) <- c("ID", "Year", "Education", "MedianIncome", "IndividualIncome")
summary(data)
# 'ID' column
count(data, ID)
# 'Year' column
count(data, Year)
# 'Education' column - Highest general school degree
count(data, Education)
data$Education[is.na(data$Education)] <- 7
# MedianIncome
count(data, MedianIncome)
summary(data$MedianIncome)
# 'IndividualIncome' column - Income
count(data, IndividualIncome)
data$IndividualIncome[is.na(data$IndividualIncome)] <- 0
summary(data$IndividualIncome)
sum(is.na(data)) #Total number of NA values in the data frame
summary(data)
########################
## Balanced Panel
########################
# Load necessary library
library(dplyr)
# Assuming your data frame is named 'data'
# Group by ID and count the number of unique years for each ID
filtered_data <- data %>%
group_by(ID) %>%
filter(n_distinct(Year) == length(2013:2023)) %>%
ungroup()
# View the filtered data
print(filtered_data)
# Filter the data to keep only IDs present in every year from 2013 to 2023
filtered_data <- data %>%
group_by(ID) %>%
filter(n_distinct(Year) == length(Years$Year)) %>%
ungroup()
# Load and clean the data
RawData <- readRDS("population.RDS")
RawData = data.frame(RawData)
data = RawData[c("id", "year","EF310", "ind.median", "inc.ind")]
colnames(data) <- c("ID", "Year", "Education", "MedianIncome", "IndividualIncome")
summary(data)
# 'ID' column
count(data, ID)
# 'Year' column
count(data, Year)
# 'Education' column - Highest general school degree
count(data, Education)
data$Education[is.na(data$Education)] <- 7
# MedianIncome
count(data, MedianIncome)
summary(data$MedianIncome)
# 'IndividualIncome' column - Income
count(data, IndividualIncome)
data$IndividualIncome[is.na(data$IndividualIncome)] <- 0
summary(data$IndividualIncome)
sum(is.na(data)) #Total number of NA values in the data frame
summary(data)
########################
## Balanced Panel
########################
# Load necessary library
library(dplyr)
# Filter the data to keep only IDs present in every year from 2013 to 2023
filtered_data <- data %>%
group_by(ID) %>%
filter(n_distinct(Year) == length(Years$Year)) %>%
ungroup()
if (all_balanced) {
print("The dataset is a balanced panel.")
} else {
print("The dataset is not a balanced panel.")
}
# Optionally, check the structure of the filtered data
print(filtered_data)
# Define the range of years
years <- 2013:2023
# Filter the data to keep only IDs present in every year from 2013 to 2023
filtered_data <- data %>%
group_by(ID) %>%
filter(n_distinct(Year) == length(years)) %>%
ungroup()
# Verify the balanced panel structure
# Count the number of records for each ID
id_counts <- filtered_data %>%
group_by(ID) %>%
summarise(count = n())
# Check if all IDs have the same number of records as there are years
all_balanced <- all(id_counts$count == length(years))
if (all_balanced) {
print("The dataset is a balanced panel.")
} else {
print("The dataset is not a balanced panel.")
}
# Optionally, check the structure of the filtered data
print(filtered_data)
summary(data)
########################
## Balanced Panel
########################
# Load necessary library
# Load necessary library
library(dplyr)
# Define the range of years we are interested in
years <- 2013:2023
# Filter the data to keep only the years from 2013 to 2023
filtered_data <- data %>%
filter(Year %in% years)
# Further filter the data to keep only IDs present in every year from 2013 to 2023
filtered_data <- filtered_data %>%
group_by(ID) %>%
filter(n_distinct(Year) == length(years)) %>%
ungroup()
# Verify the balanced panel structure
# Count the number of records for each ID
id_counts <- filtered_data %>%
group_by(ID) %>%
summarise(count = n())
# Check if all IDs have the same number of records as there are years
all_balanced <- all(id_counts$count == length(years))
if (all_balanced) {
print("The dataset is a balanced panel.")
} else {
print("The dataset is not a balanced panel.")
}
# Optionally, check the structure of the filtered data
print(filtered_data)
if (all_balanced) {
print("The dataset is a balanced panel.")
} else {
print("The dataset is not a balanced panel.")
}
########################
## Balanced Panel
########################
# Ensure the 'Year' column is numeric or integer
data$Year <- as.numeric(data$Year)
# Filter the data to keep only rows where the 'Year' is between 2013 and 2023 inclusive
filtered_data <- subset(data, Year >= 2013 & Year <= 2023)
# Print the filtered data to check the result
print(filtered_data)
# Find IDs that are present in all years between 2013 and 2023
years <- 2013:2023
common_ids <- Reduce(intersect, lapply(years, function(year) {
unique(filtered_data$ID[filtered_data$Year == year])
}))
# Filter the data to keep only rows with common IDs
final_data <- filtered_data[filtered_data$ID %in% common_ids, ]
# Print the final data to check the result
print(final_data)
# Ensure the 'Year' column is numeric
data$Year <- as.numeric(data$Year)
# Filter the data for the years 2013 to 2023
filtered_data <- subset(data, Year >= 2013 & Year <= 2023)
# Count the number of unique years each ID appears in
id_year_count <- aggregate(Year ~ ID, data = filtered_data, FUN = function(x) length(unique(x)))
# Check if every ID appears in all the years (2013 to 2023)
is_balanced_panel <- all(id_year_count$Year == length(2013:2023))
if (is_balanced_panel) {
print("The data is a balanced panel.")
} else {
print("The data is not a balanced panel.")
}
# Optionally, print the IDs that do not appear in all years
unbalanced_ids <- id_year_count$ID[id_year_count$Year != length(2013:2023)]
if (length(unbalanced_ids) > 0) {
print("IDs that do not appear in all years:")
print(unbalanced_ids)
}
# Count the number of unique years each ID appears in
id_year_count <- aggregate(Year ~ ID, data = final_data, FUN = function(x) length(unique(x)))
# Check if every ID appears in all the years (2013 to 2023)
is_balanced_panel <- all(id_year_count$Year == length(2013:2023))
if (is_balanced_panel) {
print("The data is a balanced panel.")
} else {
print("The data is not a balanced panel.")
}
# Optionally, print the IDs that do not appear in all years
unbalanced_ids <- id_year_count$ID[id_year_count$Year != length(2013:2023)]
if (length(unbalanced_ids) > 0) {
print("IDs that do not appear in all years:")
print(unbalanced_ids)
}
View(data)
########################
## Balanced Panel
########################
# Ensure the 'Year' column is numeric or integer
data <- as.numeric(data)
common_ids <- Reduce(intersect, lapply(years, function(year) {
unique(filtered_data$ID[filtered_data$Year == year])
}))
# Filter the data to keep only rows with common IDs
final_data <- filtered_data[filtered_data$ID %in% common_ids, ]
# Print the final data to check the result
print(final_data)
# Count the number of unique years each ID appears in
id_year_count <- aggregate(Year ~ ID, data = final_data, FUN = function(x) length(unique(x)))
# Check if every ID appears in all the years (2013 to 2023)
is_balanced_panel <- all(id_year_count$Year == length(2013:2023))
if (is_balanced_panel) {
print("The data is a balanced panel.")
} else {
print("The data is not a balanced panel.")
}
# Optionally, print the IDs that do not appear in all years
unbalanced_ids <- id_year_count$ID[id_year_count$Year != length(2013:2023)]
if (length(unbalanced_ids) > 0) {
print("IDs that do not appear in all years:")
print(unbalanced_ids)
}
# Check if every ID appears in all the years (2013 to 2023)
is_balanced_panel <- all(id_year_count$Year == length(2013:2023))
if (is_balanced_panel) {
print("The data is a balanced panel.")
} else {
print("The data is not a balanced panel.")
}
# Optionally, print the IDs that do not appear in all years
unbalanced_ids <- id_year_count$ID[id_year_count$Year != length(2013:2023)]
if (length(unbalanced_ids) > 0) {
print("IDs that do not appear in all years:")
print(unbalanced_ids)
}
# Load and clean the data
RawData <- readRDS("population.RDS")
RawData = data.frame(RawData)
data = RawData[c("id", "year","EF310", "ind.median", "inc.ind")]
colnames(data) <- c("ID", "Year", "Education", "MedianIncome", "IndividualIncome")
summary(data)
# 'ID' column
count(data, ID)
# 'Year' column
count(data, Year)
data <- subset(data, Year >= 2013 & Year <= 2023) # Filter the data to keep only rows where the 'Year' is between 2013 and 2023 inclusive
# 'Education' column - Highest general school degree
count(data, Education)
data$Education[is.na(data$Education)] <- 7
# MedianIncome
count(data, MedianIncome)
summary(data$MedianIncome)
# 'IndividualIncome' column - Income
count(data, IndividualIncome)
data$IndividualIncome[is.na(data$IndividualIncome)] <- 0
summary(data$IndividualIncome)
sum(is.na(data)) #Total number of NA values in the data frame
summary(data)
########################
## Balanced Panel
########################
# Ensure the 'Year' column is numeric or integer
data$Year <- as.numeric(data$Year)
# Find IDs that are present in all years between 2013 and 2023
years <- 2013:2023
common_ids <- Reduce(intersect, lapply(years, function(year) {
unique(data$ID[data$Year == year])
}))
# Filter the data to keep only rows with common IDs
BalancedPanel <- data[data$ID %in% common_ids, ]
# Print the final data to check the result
print(BalancedPanel)
# Count the number of unique years each ID appears in
id_year_count <- aggregate(Year ~ ID, data = BalancedPanel, FUN = function(x) length(unique(x)))
# Check if every ID appears in all the years (2013 to 2023)
is_balanced_panel <- all(id_year_count$Year == length(2013:2023))
if (is_balanced_panel) {
print("The data is a balanced panel.")
} else {
print("The data is not a balanced panel.")
}
# Optionally, print the IDs that do not appear in all years
unbalanced_ids <- id_year_count$ID[id_year_count$Year != length(2013:2023)]
if (length(unbalanced_ids) > 0) {
print("IDs that do not appear in all years:")
print(unbalanced_ids)
}
unbalanced_ids
View(BalancedPanel)
# 'Year' column
count(data, Year)
id_year_count
is_balanced_panel
###################################
## Tipu Sultan
###################################
# Set Directory
setwd("/Users/tipusultan/Documents/GitHub/Imputation-of-Panel-Data")
########################
## Data
########################
library(dplyr)
library(readxl)
# Load and clean the data
RawData <- readRDS("population.RDS")
RawData = data.frame(RawData)
data = RawData[c("id", "year","EF310", "ind.median", "inc.ind")]
colnames(data) <- c("ID", "Year", "Education", "MedianIncome", "IndividualIncome")
summary(data)
# 'ID' column
count(data, ID)
# 'Year' column
count(data, Year)
data <- subset(data, Year >= 2013 & Year <= 2023) # Filter the data to keep only rows where the 'Year' is between 2013 and 2023 inclusive
# 'Education' column - Highest general school degree
count(data, Education)
data$Education[is.na(data$Education)] <- 7
# MedianIncome
count(data, MedianIncome)
summary(data$MedianIncome)
# 'IndividualIncome' column - Income
count(data, IndividualIncome)
data$IndividualIncome[is.na(data$IndividualIncome)] <- 0
summary(data$IndividualIncome)
sum(is.na(data)) #Total number of NA values in the data frame
summary(data)
########################
## Balanced Panel
########################
# Ensure the 'Year' column is numeric or integer
data$Year <- as.numeric(data$Year)
# Find IDs that are present in all years between 2013 and 2023
years <- 2013:2023
common_ids <- Reduce(intersect, lapply(years, function(year) {
unique(data$ID[data$Year == year])
}))
# Filter the data to keep only rows with common IDs
BalancedPanel <- data[data$ID %in% common_ids, ]
# Print the final data to check the result
print(BalancedPanel)
# Count the number of unique years each ID appears in
id_year_count <- aggregate(Year ~ ID, data = BalancedPanel, FUN = function(x) length(unique(x)))
# Check if every ID appears in all the years (2013 to 2023)
is_balanced_panel <- all(id_year_count$Year == length(2013:2023))
if (is_balanced_panel) {
print("The data is a balanced panel.")
} else {
print("The data is not a balanced panel.")
}
# Optionally, print the IDs that do not appear in all years
unbalanced_ids <- id_year_count$ID[id_year_count$Year != length(2013:2023)]
if (length(unbalanced_ids) > 0) {
print("IDs that do not appear in all years:")
print(unbalanced_ids)
}
id_year_count
if (is_balanced_panel) {
print("The data is a balanced panel.")
}
else {
if (is_balanced_panel) {
print("The data is a balanced panel.")
} else {
print("The data is not a balanced panel.")
}
# Optionally, print the IDs that do not appear in all years
unbalanced_ids <- id_year_count$ID[id_year_count$Year != length(2013:2023)]
if (length(unbalanced_ids) > 0) {
print("IDs that do not appear in all years:")
print(unbalanced_ids)
}
UnbalancedPanel <- data
# Count the number of unique years each ID appears in
id_year_count <- aggregate(Year ~ ID, data = UnbalancedPanel, FUN = function(x) length(unique(x)))
# Check if every ID appears in all the years (2013 to 2023)
is_balanced_panel <- all(id_year_count$Year == length(2013:2023))
if (is_balanced_panel) {
print("The data is a balanced panel.")
} else {
print("The data is not a balanced panel.")
}
# Optionally, print the IDs that do not appear in all years
unbalanced_ids <- id_year_count$ID[id_year_count$Year != length(2013:2023)]
if (length(unbalanced_ids) > 0) {
print("IDs that do not appear in all years:")
print(unbalanced_ids)
}
'fsdfsdfs
dfsdfsdf'
'kdfjnsdnfaksjdnfjksdnf
dsfsdmbfmansdbfmnasdf'
'kdfjnsdnfaksjdnfjksdnf
dsfsdmbfmansdbfmnasdf'
