covid_data_omited <- covid_data[!(is.na(covid_data$continent) | covid_data$continent==""), ]
covid_data_aggregated <- aggregate(new_cases~location+continent, covid_data_omited, sum)
covid_data_ordered <- covid_data_aggregated[order(covid_data_aggregated$new_cases,decreasing = TRUE),]
covid_data_top_10 <- covid_data_ordered[1:10,]
covid_data_top_10
## Find the stacked area chart
library(ggplot2)
continent<-covid_data_top_10$continent
location<-covid_data_top_10$location
location<-as.numeric(factor(location))
new_cases<-covid_data_top_10$new_cases
data_new<- data.frame(location,new_cases,continent)
plot<-ggplot(data = data_new,
aes(x=location,
y=new_cases,
fill=continent,
))
stack_area_chart<-plot+geom_area(aes(color=continent,fill=continent))
stack_area_chart
load("bestCity.Rda")
library(dplyr)
# load helper functions.
load(url("https://userpage.fu-berlin.de/soga/300/30100_data_sets/helper_functions_30300.RData"))
rownames(bestCity) <- bestCity$X
bestCity<-bestCity[,2:13]
prcomp(bestCity,center=TRUE,scale=FALSE,retx=FALSE)      ## scale = FALSE for Covariance-PCA
pca.cov <- prcomp(bestCity)
pca.cov
prcomp(bestCity, retx=FALSE, center=TRUE, scale=TRUE)  ## scale = TRUE for Correlation-PCA
pca.cor <- prcomp(bestCity)
pca.cor
bestCity.c.cov <- scale(bestCity, center=TRUE, scale = FALSE) # centering of the columns
apply(bestCity.c.cov, 2 ,var) # variance are significantly different
load("UKZ.Rda")
UKZ.c <- scale(UKZ, center=TRUE, scale=FALSE) # centering of the columns
knitr::opts_chunk$set(echo = TRUE)
load("bestCity.Rda")
library(dplyr)
rownames(bestCity) <- bestCity$X
bestCity<-bestCity[,2:13]
prcomp(bestCity,center=TRUE,scale=FALSE,retx=FALSE)      ## scale = FALSE for Covariance-PCA
pca.cov <- prcomp(bestCity)
pca.cov
prcomp(bestCity, retx=FALSE, center=TRUE, scale=TRUE)  ## scale = TRUE for Correlation-PCA
pca.cor <- prcomp(bestCity)
pca.cor
bestCity.c.cov <- scale(bestCity, center=TRUE, scale = FALSE) # centering of the columns
bestCity.pca <- bestCity[,1:ncol(bestCity)] %>%
apply(MARGIN = 2, FUN = center) %>%
apply(MARGIN = 2, FUN = scale)
dim(bestCity.pca)
load("UKZ.Rda")
View(UKZ)
pairs(UKZ)
?prcomp
prcomp(UKZ,center=TRUE,scale=FALSE,retx=FALSE)      # scale = FALSE for Covariance-PCA
pca.cov <- prcomp(UKZ)
summary(pca.cov)
UKZ.c <- scale(UKZ, center=TRUE, scale=FALSE) # centering of the columns
UKZ.c <- scale(UKZ, center=TRUE, scale=FALSE) # centering of the columns
## Exercise 2.1 a)
gerwd()
## Exercise 2.1 a)
getwd()
knitr::opts_chunk$set(echo = TRUE)
load("bestCity.Rda")
library(dplyr)
rownames(bestCity) <- bestCity$X
bestCity<-bestCity[,2:13]
prcomp(bestCity,center=TRUE,scale=FALSE,retx=FALSE)      ## scale = FALSE for Covariance-PCA
pca.cov <- prcomp(bestCity)
pca.cov
prcomp(bestCity, retx=FALSE, center=TRUE, scale=TRUE)  ## scale = TRUE for Correlation-PCA
pca.cor <- prcomp(bestCity)
pca.cor
bestCity.c.cov <- scale(bestCity, center=TRUE, scale = FALSE) # centering of the columns
apply(bestCity.c.cov, 2 ,var) # variance are significantly different
knitr::opts_chunk$set(echo = TRUE)
load("bestCity.Rda")
library(dplyr)
rownames(bestCity) <- bestCity$X
bestCity<-bestCity[,2:13]
prcomp(bestCity,center=TRUE,scale=FALSE,retx=FALSE)      ## scale = FALSE for Covariance-PCA
pca.cov <- prcomp(bestCity)
pca.cov
prcomp(bestCity, retx=FALSE, center=TRUE, scale=TRUE)  ## scale = TRUE for Correlation-PCA
pca.cor <- prcomp(bestCity)
pca.cor
bestCity.c.cov <- scale(bestCity, center=TRUE, scale = FALSE) # centering of the columns
apply(bestCity.c.cov, 2 ,var) # variance are significantly different
bestCity.c.cov <- scale(bestCity, center=TRUE, scale = FALSE) # centering of the columns
getwd()
setwd("/Users/tipusultan")
load("bestCity.Rda")
getwd()
knitr::opts_chunk$set(echo = TRUE)
load("bestCity.Rda")
library(dplyr)
rownames(bestCity) <- bestCity$X
bestCity<-bestCity[,2:13]
prcomp(bestCity,center=TRUE,scale=FALSE,retx=FALSE)      ## scale = FALSE for Covariance-PCA
pca.cov <- prcomp(bestCity)
pca.cov
prcomp(bestCity, retx=FALSE, center=TRUE, scale=TRUE)  ## scale = TRUE for Correlation-PCA
prcomp(bestCity, retx=FALSE, center=TRUE, scale=TRUE)  ## scale = TRUE for Correlation-PCA
pca.cor <- prcomp(bestCity)
pca.cor
bestCity.c.cov <- scale(bestCity, center=TRUE, scale = FALSE) # centering of the columns
apply(bestCity.c.cov, 2 ,var) # variance are significantly different
bestCity.c.cor <- scale(bestCity, center=TRUE, scale=TRUE) # centering of the columns
apply(bestCity.c.cor, 2 ,var) # variance are well standardized.
biplot(pca.cov)
biplot(pca.cov)
biplot(pca.cor)
# load helper functions.
load(url("https://userpage.fu-berlin.de/soga/300/30100_data_sets/helper_functions_30300.RData"))
bestCity.pca <- bestCity[,1:ncol(bestCity)] %>%
apply(MARGIN = 2, FUN = center) %>%
apply(MARGIN = 2, FUN = scale)
dim(bestCity.pca)
bestCity.pca.eigen <- eigen(cov(bestCity.pca))
bestCity.pca.eigen$values
cumsum(bestCity.pca.eigen$values/sum(bestCity.pca.eigen$values))
a<-c(1,2,3,4)
x*3
y=x*3
fahrenheit_to_celsius <- function(temp_F) {
temp_C <- (temp_F - 32) * 5 / 9
return(temp_C)
}
mul_by_3 <- function(x) {
y=x*3
}
mul_by_3 <- function(x) {
y=x*3
}
mul_by_3(2)
mul_by_3 <- function(x) {
y=x*3
return(y)
}
mul_by_3(2)
a
a = 5
a
getwd()
sink()
a = 5
getwd()
exit(sink())
a
a
for i in range(1:6){
i**2
}
exit(sink())
1:50%in%c(3,10,7)
length(1:50%in%c(3,10,7))
abc -> list(1,2,3,4,5,6,7,8,9)
abc = list(1,2,3,4,5,6,7,8,9)
abc[[c(3,4)]]
abc = list(1,2,3,4,5,6,7,8,9)
abc[[c(3,4)]]
abc
as.numeric(factor(c(3,1,4,1,5)))
is.list(abc[1])
?sample
12*4*10
12*4*10000
getwd()
x = c(1,2,3)
plot(x)
getwd()
setwd("/Users/tipusultan/Documents/GitHub/Imputation-of-Panel-Data")
getwd()
# Load Data
LifeExpectancy -> read.excel('life expectancy')
# Load Data
LifeExpectancy <- read.excel('life expectancy')
library("readxl", lib.loc="/opt/anaconda3/envs/rstudio/lib/R/library")
# Load Data
LifeExpectancy <- read.excel('life expectancy')
# Load Data
LifeExpectancy <- read_excel('life expectancy')
# Load Data
LifeExpectancy <- read_excel('life expectancy.xlsx')
View(LifeExpectancy)
View(LifeExpectancy)
install.packages("dplyr")
library(dplyr)
LifeExpectancy <- arrange(LifeExpectancy, Country Name)
LifeExpectancy <- arrange(LifeExpectancy, CountryName)
head(LifeExpectancy)
LifeExpectancy <- as.data.frame(LifeExpectancy)
View(LifeExpectancy)
head(LifeExpectancy)
LifeExpectancy <- LifeExpectancy[-1, ]
View(LifeExpectancy)
# Load Data
LifeExpectancy <- read_excel('life expectancy.xlsx')
# Load Data
LifeExpectancy <- read_excel('life expectancy.xlsx')
install.packages("readxl")
library(readxl)
# Load Data
LifeExpectancy <- read_excel('life expectancy.xlsx')
LifeExpectancy <- as.data.frame(LifeExpectancy)
LifeExpectancy <- LifeExpectancy[-1, ]
View(LifeExpectancy)
# Load Data
LifeExpectancy <- read_excel('life expectancy.xlsx')
LifeExpectancy <- as.data.frame(LifeExpectancy)
LifeExpectancy <- arrange(LifeExpectancy, Country Name)
# Load Data
LifeExpectancy <- read_excel('life expectancy.xlsx', header = FALSE)
# Load Data
LifeExpectancy <- read.csv('life expectancy.xlsx', header = FALSE)
LifeExpectancy <- as.data.frame(LifeExpectancy)
View(LifeExpectancy)
# Load Data
LifeExpectancy <- read_excel('life expectancy.xlsx')
LifeExpectancy <- as.data.frame(LifeExpectancy)
View(LifeExpectancy)
colnames(LifeExpectancy) <- NULL
View(LifeExpectancy)
# Identify rows where column names contain the specified substring
rows_to_remove <- grepl("substring_to_remove", colnames(LifeExpectancy))
# Remove rows based on identified indices
LifeExpectancy <- LifeExpectancy[!rows_to_remove, ]
View(LifeExpectancy)
# Load Data
LifeExpectancy <- read_excel('life expectancy.xlsx', col_names = FALSE)
LifeExpectancy <- as.data.frame(LifeExpectancy)
View(LifeExpectancy)
LifeExpectancy <- as.data.frame(LifeExpectancy)
View(LifeExpectancy)
LifeExpectancy <- LifeExpectancy[-1, ]
View(LifeExpectancy)
# Set the first row as column names
colnames(LifeExpectancy) <- LifeExpectancy[1, ]
View(LifeExpectancy)
# Remove the first row
LifeExpectancy <- LifeExpectancy[-1, ]
View(LifeExpectancy)
LifeExpectancy <- arrange(LifeExpectancy, Country Name)
LifeExpectancy <- arrange(LifeExpectancy, desc(Country Name))
LifeExpectancy <- arrange(LifeExpectancy, desc(Country Name))
# Sort the data frame by CountryName
LifeExpectancy <- df[order(df$Country Name), ]
# Sort the data frame by CountryName
LifeExpectancy <- df[order(df$CountryName), ]
# Sort the dataset by the "Country Name" column in descending order
sorted_data <- arrange(LifeExpectancy, desc(Country.Name))
# View the sorted dataset
View(sorted_data)
# Sort the dataset by the "Country Name" column in descending order
sorted_data <- arrange(LifeExpectancy, desc(Country Name))
LifeExpectancy <- LifeExpectancy[-1, ]
View(LifeExpectancy)
LifeExpectancy <- LifeExpectancy[order(df$Country.Name), ]
LifeExpectancy <- LifeExpectancy[order(LifeExpectancy$`Country Name`), ]
View(LifeExpectancy)
LifeExpectancy <- LifeExpectancy['Country Name', 'Year', 'Health Expenditure %', 'Unemployment' ]
LifeExpectancy <- LifeExpectancy['Country Name', 'Year', 'Health Expenditure %', 'Unemployment' ]
LifeExpectancy <- LifeExpectancy['Country Name', 'Year', 'Health Expenditure %', 'Unemployment']
LifeExpectancy <- LifeExpectancy['Country Name', 'Year', 'Health Expenditure %']
LifeExpectancy <- LifeExpectancy[, c('Country Name', 'Year', 'Health Expenditure %')]
View(LifeExpectancy)
unique_ids <- unique(panel_data$Country.Name)
unique_ids <- unique(LifeExpectancy$Country.Name)
unique_times <- unique(LifeExpectancy$Year)
# Load necessary packages
library(dplyr)
# Identify unique countries and years
unique_countries <- unique(LifeExpectancy$`Country Name`)
unique_years <- unique(LifeExpectancy$Year)
# Create a data frame to store the balanced panel data
balanced_panel <- data.frame()
# Loop through each country and year to check for missing observations
for (country in unique_countries) {
for (year in unique_years) {
# Check if the combination of country and year exists in the original data
if (sum(LifeExpectancy$`Country Name` == country & LifeExpectancy$Year == year) == 0) {
# If the combination is missing, create a row of NA values for that combination
missing_row <- data.frame(`Country Name` = country, Year = year, `Health Expenditure %` = NA)
balanced_panel <- bind_rows(balanced_panel, missing_row)
}
}
}
# Merge the original data with the missing observations to create the balanced panel
balanced_panel <- merge(LifeExpectancy, balanced_panel, by = c("Country Name", "Year"), all = TRUE)
# Sort the data frame by country and year
balanced_panel <- balanced_panel[order(balanced_panel$`Country Name`, balanced_panel$Year), ]
# Rename the columns in the balanced panel to match LifeExpectancy
names(balanced_panel)[names(balanced_panel) == "Health Expenditure %"] <- "Health_Expenditure"
# Merge the original data with the missing observations to create the balanced panel
balanced_panel <- merge(LifeExpectancy, balanced_panel, by = c("Country Name", "Year"), all = TRUE)
# Sort the data frame by country and year
balanced_panel <- balanced_panel[order(balanced_panel$`Country Name`, balanced_panel$Year), ]
# Rename the columns in the balanced panel to match LifeExpectancy
names(balanced_panel)[names(balanced_panel) == "Health Expenditure %"] <- "Health_Expenditure"
# Merge the original data with the missing observations to create the balanced panel
balanced_panel <- merge(LifeExpectancy, balanced_panel, by = c("Country Name", "Year"), all = TRUE)
# Sort the data frame by country and year
balanced_panel <- balanced_panel[order(balanced_panel$`Country Name`, balanced_panel$Year), ]
# Rename the column in the balanced panel to match LifeExpectancy
names(balanced_panel)[names(balanced_panel) == "Health Expenditure %"] <- "Health_Expenditure"
# Check the column names of both datasets
print(colnames(LifeExpectancy))
print(colnames(balanced_panel))
# Merge the original data with the missing observations to create the balanced panel
balanced_panel <- merge(balanced_panel, LifeExpectancy, by = c("Country Name", "Year"), all = TRUE)
View(balanced_panel)
unique_countries
unique_years
# Loop through each country and year to check for missing observations
for (country in unique_countries) {
for (year in unique_years) {
# Check if the combination of country and year exists in the original data
if (sum(LifeExpectancy$'Country Name' == country & LifeExpectancy$'Year' == year) == 0) {
# If the combination is missing, create a row of NA values for that combination
missing_row <- data.frame('Country Name' = country, Year = year, 'Health Expenditure %' = NA)
balanced_panel <- bind_rows(balanced_panel, missing_row)
}
}
}
# Rename the column in the balanced panel to match LifeExpectancy
names(balanced_panel)[names(balanced_panel) == "Health Expenditure %"] <- "Health_Expenditure"
balanced_panel
# Check the column names of both datasets
print(colnames(LifeExpectancy))
print(colnames(balanced_panel))
View(balanced_panel)
# Load required library
library(plm)
install.packages("plm")
# Load required library
library(plm)
# Set parameters
n <- 100  # Number of individuals
T <- 5    # Number of time periods
# Generate individual and time indices
id <- rep(1:n, each = T)
time <- rep(1:T, times = n)
# Simulate individual-specific effects
alpha_i <- rnorm(n, mean = 0, sd = 1)
# Simulate time-specific effects
gamma_t <- rnorm(T, mean = 0, sd = 1)
# Generate random error term
error <- rnorm(n*T, mean = 0, sd = 1)
# Simulate balanced panel data
data_balanced <- data.frame(
id = id,
time = time,
x1 = rnorm(n*T),
x2 = rnorm(n*T),
y = 1 + 2 * x1 + 3 * x2 + alpha_i[id] + gamma_t[time] + error
)
# Convert to panel data object
balanced_panel_data <- pdata.frame(data_balanced, index = c("id", "time"))
# View the first few rows of the balanced panel data
head(balanced_panel_data)
# Set parameters
n <- 100  # Number of individuals
T <- 5    # Maximum number of time periods
# Generate random number of observations per individual
obs_per_individual <- sample(2:T, n, replace = TRUE)
# Generate individual and time indices
id <- rep(1:n, times = obs_per_individual)
time <- unlist(lapply(obs_per_individual, function(x) sample(1:T, x)))
# Simulate individual-specific effects
alpha_i <- rnorm(n, mean = 0, sd = 1)
# Simulate time-specific effects
gamma_t <- rnorm(T, mean = 0, sd = 1)
# Generate random error term
error <- rnorm(length(id), mean = 0, sd = 1)
# Simulate unbalanced panel data
data_unbalanced <- data.frame(
id = id,
time = time,
x1 = rnorm(length(id)),
x2 = rnorm(length(id)),
y = 1 + 2 * x1 + 3 * x2 + alpha_i[id] + gamma_t[time] + error
)
# Load required library
library(plm)
# Set parameters
n <- 100  # Number of individuals
T <- 5    # Number of time periods
# Generate individual and time indices
id <- rep(1:n, each = T)
time <- rep(1:T, times = n)
# Simulate individual-specific effects
alpha_i <- rnorm(n, mean = 0, sd = 1)
# Simulate time-specific effects
gamma_t <- rnorm(T, mean = 0, sd = 1)
# Generate random error term
error <- rnorm(n*T, mean = 0, sd = 1)
# Simulate balanced panel data
data_balanced <- data.frame(
id = id,
time = time,
x1 = rnorm(n*T),
x2 = rnorm(n*T),
y = 1 + 2 * data_balanced$x1 + 3 * data_balanced$x2 + alpha_i[id] + gamma_t[time] + error
)
# Simulate balanced panel data
data_balanced <- data.frame(
id = id,
time = time,
x1 = rnorm(n*T),
x2 = rnorm(n*T),
y = 1 + 2 * data_balanced$x1 + 3 * data_balanced$x2 + alpha_i[id] + gamma_t[time] + error
)
# Convert to panel data object
balanced_panel_data <- pdata.frame(data_balanced, index = c("id", "time"))
# Load required library
library(plm)
# Set parameters
n <- 100  # Number of individuals
T <- 5    # Number of time periods
# Generate individual and time indices
id <- rep(1:n, each = T)
time <- rep(1:T, times = n)
# Simulate individual-specific effects
alpha_i <- rnorm(n, mean = 0, sd = 1)
# Simulate time-specific effects
gamma_t <- rnorm(T, mean = 0, sd = 1)
# Generate random error term
error <- rnorm(n*T, mean = 0, sd = 1)
# Simulate balanced panel data
data_balanced <- data.frame(
id = id,
time = time,
x1 = rnorm(n*T),
x2 = rnorm(n*T),
y = 1 + 2 * data_balanced$x1 + 3 * data_balanced$x2 + alpha_i[id] + gamma_t[time] + error
)
# Simulate balanced panel data
data_balanced <- data.frame(
id = id,
time = time,
x1 = rnorm(n*T),
x2 = rnorm(n*T),
y = 1 + 2 * data_balanced$x1 + 3 * data_balanced$x2 + alpha_i[id] + gamma_t[time] + error
)
# Simulate balanced panel data
data_balanced <- data.frame(id = id,time = time,x1 = rnorm(n*T),x2 = rnorm(n*T),
y = 1 + 2 * data_balanced$x1 + 3 * data_balanced$x2 + alpha_i[id] + gamma_t[time] + error)
# Generate individual and time indices
id <- rep(1:n, each = T)
time <- rep(1:T, times = n)
# Simulate individual-specific effects
alpha_i <- rnorm(n, mean = 0, sd = 1)
# Simulate time-specific effects
gamma_t <- rnorm(T, mean = 0, sd = 1)
# Generate random error term
error <- rnorm(n*T, mean = 0, sd = 1)
# Simulate balanced panel data
data_balanced <- data.frame(id = id,time = time,x1 = rnorm(n*T),x2 = rnorm(n*T),
y = 1 + 2 * data_balanced$x1 + 3 * data_balanced$x2 + alpha_i[id] + gamma_t[time] + error)
# Set parameters
n <- 100  # Number of individuals
T <- 5    # Number of time periods
# Generate individual and time indices
id <- rep(1:n, each = T)
time <- rep(1:T, times = n)
# Simulate individual-specific effects
alpha_i <- rnorm(n, mean = 0, sd = 1)
# Simulate time-specific effects
gamma_t <- rnorm(T, mean = 0, sd = 1)
# Generate random error term
error <- rnorm(n*T, mean = 0, sd = 1)
# Simulate balanced panel data
data_balanced <- data.frame(
id = id,
time = time,
x1 = rnorm(n*T),
x2 = rnorm(n*T),
y = 1 + 2 * rnorm(n*T) + 3 * rnorm(n*T) + alpha_i[id] + gamma_t[time] + error
)
# Convert to panel data object
balanced_panel_data <- pdata.frame(data_balanced, index = c("id", "time"))
# View the first few rows of the balanced panel data
head(balanced_panel_data)
# Set parameters
n <- 100  # Number of individuals
T <- 5    # Maximum number of time periods
# Generate random number of observations per individual
obs_per_individual <- sample(2:T, n, replace = TRUE)
# Generate individual and time indices
id <- rep(1:n, times = obs_per_individual)
time <- unlist(lapply(obs_per_individual, function(x) sample(1:T, x)))
# Simulate individual-specific effects
alpha_i <- rnorm(n, mean = 0, sd = 1)
# Simulate time-specific effects
gamma_t <- rnorm(T, mean = 0, sd = 1)
# Generate random error term
error <- rnorm(length(id), mean = 0, sd = 1)
# Simulate unbalanced panel data
data_unbalanced <- data.frame(
id = id,
time = time,
x1 = rnorm(length(id)),
x2 = rnorm(length(id)),
y = 1 + 2 * rnorm(length(id)) + 3 * rnorm(length(id)) + alpha_i[id] + gamma_t[time] + error
)
# Convert to panel data object
unbalanced_panel_data <- pdata.frame(data_unbalanced, index = c("id", "time"))
# View the first few rows of the unbalanced panel data
head(unbalanced_panel_data)
View(unbalanced_panel_data)
